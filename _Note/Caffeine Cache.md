### Eviction Policy
Thông thường các thuật toán cache sẽ dự đoán xem phần tử nào có vẻ sẽ được sử dụng ở tương lai gần để giữ lại. LRU là một thuật toán nổi tiếng vì tính đơn giản, hiệu năng tốt và decent hit rate trong đa số trường hợp. Khả năng dự đoán của nó bị giới hạn bởi lịch sử các phần tử được lưu trong cache.

Modern cache sẽ gia tăng lịch sử sử dụng để có thể bao quát được nhiều phần tử hơn dựa trên recency và frequency. Một cách tiếp cận để bao quát lịch sử là sử dụng một sketch nổi tiếng (phức tạp, probabilistic data sturture - cấu trúc xác suất) để xác định các phần tử "heavy hitters" trong một luồng lớn các event. Ví dụ là [CountMin Sketch](http://dimacs.rutgers.edu/~graham/pubs/papers/cmsoft.pdf), sử dụng một ma trận đếm và các hàm hash. Thêm vào đó là sự gia tăng của một số phần tử ngẫu nhiên và frequency được dự đoán thấp hơn. Điều đó sẽ dẫn đến việc chúng ta phải lựa chọn giữa các yếu tố memory, hiệu năng, và khả năng xảy ra lỗi bằng cách điều chỉnh độ dài rộng của ma trận

Window TinyLFU sử dụng sketch đó như là một bộ lọc, chấp nhận rằng nếu một phần tử mới có một tầng suất cao hơn phần tử có thể bị loại bỏ. Thay vì lọc ngay lập tức, thuật toán sẽ cho phần tử sắp bị loại bỏ đó một cơ hội để tăng "độ nổi tiếng". Điều này tránh các trường hợp loại bỏ nhầm, đặc biệt là các trường hợp phần tử thưa thớt nơi mà các phần tử không phù hợp với long-term. Để giữ lịch sử luôn tươi mới thì một aging process sẽ thực thi định kì hoặc từng bước cắt giảm 1 nửa các bộ đếm.

W-TinyLFU sử dụng Segmented LRU (SLRU) cho các phần tử long-term. Một phần tử bắt đầu trong một vùng ngẫu nhiên (probationary segment) và về sau sẽ được đưa vào protected segment (chiếm 80%). Một khi protected segment full thì sẽ đưa ngược về các probationary segment, nơi mà một phần tử ngẫu nhiên nào đó sẽ bị loại bỏ. Điều này đảm bảo rằng các phần tử với tần suất truy cập lớn sẽ được giữ lại và các phần tử ít xài sẽ bị loại bỏ.

Như database và search trace thể hiện, có rất nhiều điều để cải thiện từ LRU bằng cách phân tích sâu vào recency và frequency. Các thuật toán cấp cao khác là ẢC, LIRS và W-TinyLFU đều thu nhỏ giới hạn để cung cấp hit rate tốt nhất có thể.

### Expiration Policy
Expiration thường được implemented as variable per entry và các expired entry sẽ được loại bỏ một cách lazy dựa vào capacity. Điều này sẽ gây ra sự thừa thải cache với các entry rác, nên đôi khi sẽ có một thread dọn rác được sử dụng để làm sạch cache và thu thập lại free space. Strategy này có xu hướng sẽ hoạt động tốt hơn với việc sắp xếp các entry theo expiration time trên một priority queue từ đó ẩn được cost khỏi user thay vì phải xử lý ở mỗi lần read, write.

Caffeine có một hướng tiếp cận khác bằng cách quan sát đưa ra một khoản thời gian cố định là điều tốt hơn. Điều này cho phép việc tổ chức các entry với độ phức tạp O(1) thời gian trong hàng đợi. A time to live duration là write order queue và time to idle uration là một access order queue. Cache có thể sử dụng lại các hàng đợi eviction policy và các cơ chế thực thi đồng thời được miêu tả ở dưới, từ đó thì các expired entry có thể bị loại bỏ trong maintain phase của cache. 

### Concurrency
Concurent access vào cache là một vấn đề khó bởi hầu hết các policy thì các access đều là write đối với một số state. Giải pháp truyền thống là bảo vệ cache với single lock. Điều này có thể được cải thiện bằng cách chia nhỏ cache ra thành các vùng độc lập. Không may là là điều đó sẽ dẫn đến một số hạn chế bởi vì các hot entry sẽ chiếm lock nhiều hơn các lượng còn lại. Khi vấn đề xảy ra dẫn đến tắc nghẽn thì việc xử lý là phải update only per entry metadata và sử dụng random sampling hoặc FIFO-based eviction policy. Các kĩ thuật đó có thể đạt được hiệu năng đọc tốt, nhưng write thì tệ, và cái khó là trong việc chọn good victim.

Một giải pháp thay thế là lấy cảm hứng từ các giả thuyết database sử dụng commit log để write. Thay vì phải cập nhật data stucture ngay lập tức thì các cập nhật có thể được viết thành log và được thì thực một cách bất đồng bộ. Ý tưởng tương tự cũng được áp dụng cho cache bằng cách thực thi các thao tác trên hash table, recording các thao tác vào buffer, và lên lịch replay activity để phục vụ cho policy khi cần thiết. Các policy vẫn được đảm bảo bởi lock, hoặc try lock sẽ chắc chắn hơn nhưng thay vì tranh chấp thì sẽ tạo log buffer.

Trong Caffeine thì các buffer sẽ được chia ra và sử dụng cho việc read và write. Các access sẽ được record vào striped ring buffer nơi mà các stripe sẽ được chọn bởi một thread hash và số lượng stripe sẽ gia tăng dựa vào các tranh chấp được phát hiện. Khi mà ring buffer full, một asynchronous drain được lên lịch và subsequent addition to buffer sẽ được loại bỏ đến khi nào có chỗ trống. Khi mà access không được ghi lại lúc buffer full thì cache value vẫn được trả về caller. The loss of policy information không đủ ý nghĩa tác động bởi vì W-TinyLFU có thể xác định các hot entry mà chúng ta muốn giữ lại. Bằng cachs ử dụng thread-specific hash thay vì key's hash thì cache sẽ tránh được các popular entry khỏi các nguyên nhân dẫn đến tranh chấp bằng cách chia đều out the load

Trong trường hợp write truyền thống vào concurrent queue được sử dụng và mỗi thay đổi sẽ lên lịch thay đổi. Trong khi data loss không được chấp thuận, vẫn còn có cách tối ưu write buffer. Cả 2 loại buffer đều được write bởi các thread khác nhau nhưng chỉ được consumed bởi một thread duy nhất tại một thời điểm. Việc multi producer/single consumer trên sẽ giúp cho thuật toán triển khai đơn giản hơn và hiệu quả hơn.

Buffer ... Các thao tác insert, read, update, remove đều có thể được thực thi lại theo một thứ tự bất kì và nếu có bất kì sai sót gì thì policy có thể giữ lại các dangling references đó.